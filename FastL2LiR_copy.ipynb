{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jatin-Khiyani/Visual-Situmlai-Reconstruction-Using-fMRI-and-Deep-Learning/blob/main/FastL2LiR_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35be8fe3-76f6-4fd2-b527-bd313c3bfa85",
      "metadata": {
        "id": "35be8fe3-76f6-4fd2-b527-bd313c3bfa85"
      },
      "source": [
        "# Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wWtaJIYb5JdX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWtaJIYb5JdX",
        "outputId": "12e7c125-18c3-4f59-90ca-a3856bc05614"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63ae88c-a9bb-49b9-a6d1-30ed095b781c",
      "metadata": {
        "id": "d63ae88c-a9bb-49b9-a6d1-30ed095b781c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c55769e2-580d-4372-80ee-14fa8d01dd76",
      "metadata": {
        "id": "c55769e2-580d-4372-80ee-14fa8d01dd76"
      },
      "source": [
        "## Importing Captions and fMRI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d86e039-2955-4c08-aaa0-9aa1b1046b69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6d86e039-2955-4c08-aaa0-9aa1b1046b69",
        "outputId": "b944711f-c541-4441-96c8-a6b8b54d9767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fMRI shape: (27750, 215, 200)\n",
            "CLIP text embeddings shape: (27892, 7680)\n",
            "VQ-VAE latents shape: (27750, 16384)\n"
          ]
        }
      ],
      "source": [
        "fmri = np.load('/content/drive/MyDrive/NSD_Dataset/fmri.npy').astype(np.float32)\n",
        "clip_text = np.load('/content/drive/MyDrive/NSD_Dataset/Caption Embdedding.npy').astype(np.float32)\n",
        "vqvae_latents = np.load('/content/drive/MyDrive/NSD_Dataset/z.npy').astype(np.float32)\n",
        "# === Print shapes ===\n",
        "print(\"fMRI shape:\", fmri.shape)\n",
        "print(\"CLIP text embeddings shape:\", clip_text.shape)\n",
        "print(\"VQ-VAE latents shape:\", vqvae_latents.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b25b3c4-d937-4f58-89d2-9e61cebba1fa",
      "metadata": {
        "id": "4b25b3c4-d937-4f58-89d2-9e61cebba1fa"
      },
      "source": [
        "### Flattening and PreProccessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Q6w8bt-8_cNp",
      "metadata": {
        "id": "Q6w8bt-8_cNp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f9a8f7-ad36-4388-9e89-510558aaef10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47f9a8f7-ad36-4388-9e89-510558aaef10",
        "outputId": "e9af2b2c-bbf4-4bd2-ca97-0edac9292d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fMRI (flattened): (27750, 43000)\n",
            "CLIP text: (27750, 7680)\n",
            "VQ-VAE latents: (27750, 16384)\n"
          ]
        }
      ],
      "source": [
        "# === Flatten fMRI to (N, D_fmri) ===\n",
        "fmri_flat = fmri.reshape(fmri.shape[0], -1)  # shape: (27750, 43000)\n",
        "\n",
        "# === Clip c to match samples ===\n",
        "clip_text = clip_text[:fmri_flat.shape[0]]  # now (27750, 7680)\n",
        "\n",
        "# === Final sanity check ===\n",
        "print(\"fMRI (flattened):\", fmri_flat.shape)\n",
        "print(\"CLIP text:\", clip_text.shape)\n",
        "print(\"VQ-VAE latents:\", vqvae_latents.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1e648da-4abb-44d9-bd8b-a19061f6ab85",
      "metadata": {
        "id": "f1e648da-4abb-44d9-bd8b-a19061f6ab85"
      },
      "source": [
        "## Importing FastL2LiR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1b98f5b5-574a-4cb0-8e18-be7b806adf83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b98f5b5-574a-4cb0-8e18-be7b806adf83",
        "outputId": "ab68fb40-e436-4bc5-e02b-23406e62c0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 28/28 [00:03<00:00,  8.37chunk/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted shape: (27750, 16384)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ─── your RidgeDual class (as defined above) ─────────────────────────────────\n",
        "\n",
        "class RidgeDual:\n",
        "    def __init__(self, alpha=1.0, device=None):\n",
        "        self.alpha = alpha\n",
        "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.W = None\n",
        "        self.b = None\n",
        "\n",
        "    def fit(self, X_np, Y_np):\n",
        "        # X: (N, D), Y: (N, T)\n",
        "        X = torch.from_numpy(X_np).float().to(self.device)\n",
        "        Y = torch.from_numpy(Y_np).float().to(self.device)\n",
        "\n",
        "        # Center data\n",
        "        X_mean = X.mean(dim=0, keepdim=True)\n",
        "        Y_mean = Y.mean(dim=0, keepdim=True)\n",
        "        Xc = X - X_mean\n",
        "        Yc = Y - Y_mean\n",
        "\n",
        "        N, D = Xc.shape\n",
        "\n",
        "        # Compute (X X^T + αI) and solve for A\n",
        "        K = Xc @ Xc.T                    # (N, N)\n",
        "        A = torch.linalg.solve(\n",
        "            K + self.alpha * torch.eye(N, device=self.device),\n",
        "            Yc\n",
        "        )                                # (N, T)\n",
        "\n",
        "        # Recover W and b\n",
        "        self.W = Xc.T @ A                # (D, T)\n",
        "        self.b = (Y_mean - X_mean @ self.W).squeeze(0)  # (T,)\n",
        "\n",
        "    def predict(self, X_np, chunk_size=None):\n",
        "        X = torch.from_numpy(X_np).float().to(self.device)\n",
        "        if chunk_size is None:\n",
        "            return (X @ self.W + self.b).cpu().numpy()\n",
        "\n",
        "        outs = []\n",
        "        for start in tqdm(range(0, X.size(0), chunk_size), desc=\"Predicting\", unit=\"chunk\"):\n",
        "            outs.append((X[start:start+chunk_size] @ self.W + self.b).cpu().numpy())\n",
        "        return np.vstack(outs)\n",
        "\n",
        "# ─── load your data (replace with your actual load code) ────────────────────────\n",
        "\n",
        "# ─── fit the model ───────────────────────────────────────────────────────────────\n",
        "\n",
        "model = RidgeDual(alpha=0.001)   # you can tweak alpha as needed\n",
        "model.fit(fmri_flat, vqvae_latents)\n",
        "\n",
        "# ─── (optional) predict on the same data with a progress bar ────────────────────\n",
        "\n",
        "Y_pred = model.predict(fmri_flat, chunk_size=1000)\n",
        "print(\"Predicted shape:\", Y_pred.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420deae1-df55-45c1-876b-45eda02ba771",
      "metadata": {
        "id": "420deae1-df55-45c1-876b-45eda02ba771"
      },
      "source": [
        "## Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "FeKGDogpUTgD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeKGDogpUTgD",
        "outputId": "c0faf3cc-1ba5-4280-f5e4-c59459865e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting: 100%|██████████| 28/28 [00:03<00:00,  8.36chunk/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall MSE: 5.5100e+03\n",
            "Weighted R²: -6711.4258\n",
            "Mean sample-wise ρ: 0.0121 ± 0.0549\n",
            "First 5 dims R²: [-5966.1294 -9507.328  -3979.802  -8833.873  -8673.898 ]\n",
            "Median dim R²: -5136.1836\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import torch\n",
        "\n",
        "# Assume fmri_flat, vqvae_latents are your original numpy arrays\n",
        "# and `model` is your fitted RidgeDual\n",
        "\n",
        "# 1) Predict\n",
        "Y_pred = model.predict(fmri_flat, chunk_size=1000)  # (27750, 16384)\n",
        "\n",
        "# 2) Mean Squared Error\n",
        "mse = mean_squared_error(vqvae_latents, Y_pred)\n",
        "print(f\"Overall MSE: {mse:.4e}\")\n",
        "\n",
        "# 3) R² score\n",
        "#   - 'variance_weighted' weights each latent-dimension by its variance in the data.\n",
        "r2 = r2_score(vqvae_latents, Y_pred, multioutput='variance_weighted')\n",
        "print(f\"Weighted R²: {r2:.4f}\")\n",
        "\n",
        "# 4) Sample-wise Pearson correlation\n",
        "#    (skips any all-constant vectors to avoid NaNs)\n",
        "cors = []\n",
        "for i in range(Y_pred.shape[0]):\n",
        "    y_true = vqvae_latents[i]\n",
        "    y_hat  = Y_pred[i]\n",
        "    if np.std(y_true) > 0 and np.std(y_hat) > 0:\n",
        "        cors.append(np.corrcoef(y_true, y_hat)[0,1])\n",
        "cors = np.array(cors)\n",
        "print(f\"Mean sample-wise ρ: {cors.mean():.4f} ± {cors.std():.4f}\")\n",
        "\n",
        "# 5) (Optional) Per-dimension R²\n",
        "r2_per_dim = r2_score(vqvae_latents, Y_pred, multioutput='raw_values')\n",
        "print(f\"First 5 dims R²: {r2_per_dim[:5]}\")\n",
        "print(f\"Median dim R²: {np.median(r2_per_dim):.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}